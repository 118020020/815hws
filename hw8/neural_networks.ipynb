{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://pytorch.org/tutorials/beginner/introyt/trainingyt.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 60000 instances\n",
      "Validation set has 10000 instances\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# PyTorch TensorBoard support\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from datetime import datetime\n",
    "\n",
    "# Transform to normalize the data (substract the mean)\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Create datasets for training & validation, download if necessary\n",
    "training_set = torchvision.datasets.FashionMNIST('./data', train=True, transform=transform, download=True)\n",
    "validation_set = torchvision.datasets.FashionMNIST('./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=4, shuffle=False)\n",
    "\n",
    "# Class labels\n",
    "classes = ('T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot')\n",
    "\n",
    "# Report split sizes\n",
    "print('Training set has {} instances'.format(len(training_set)))\n",
    "print('Validation set has {} instances'.format(len(validation_set)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sneaker  Ankle Boot  Coat  Sandal\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Helper function for inline image display\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "dataiter = iter(training_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "img_grid = torchvision.utils.make_grid(images)\n",
    "matplotlib_imshow(img_grid, one_channel=True)\n",
    "print('  '.join(classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "w = 28\n",
    "h = 28\n",
    "num_classes = 10\n",
    "\n",
    "# PyTorch models inherit from torch.nn.Module\n",
    "class GarmentClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GarmentClassifier, self).__init__()\n",
    "        self.input = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(w*h, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input(x)\n",
    "        x = F.tanh(self.fc1(x))\n",
    "        x = F.tanh(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = GarmentClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Optimization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This criterion computes the cross entropy loss between input logits and target.\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# We will use Stochastic Gradient Descent\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "  batch 1000 loss: 1.0082411012165249\n",
      "  batch 2000 loss: 0.6251344072613865\n",
      "  batch 3000 loss: 0.5688667633831501\n",
      "  batch 4000 loss: 0.5270487912585959\n",
      "  batch 5000 loss: 0.5203557821298018\n",
      "  batch 6000 loss: 0.4919842131733894\n",
      "  batch 7000 loss: 0.4732360770236701\n",
      "  batch 8000 loss: 0.4478088934775442\n",
      "  batch 9000 loss: 0.45714920801483094\n",
      "  batch 10000 loss: 0.4391925804109778\n",
      "  batch 11000 loss: 0.4358374422851484\n",
      "  batch 12000 loss: 0.44498146991385146\n",
      "  batch 13000 loss: 0.43405559270689265\n",
      "  batch 14000 loss: 0.4364234128408134\n",
      "  batch 15000 loss: 0.41931467372283804\n",
      "LOSS train 0.41931467372283804 valid 0.4355277717113495\n",
      "EPOCH 2:\n",
      "  batch 1000 loss: 0.39507370816508774\n",
      "  batch 2000 loss: 0.3949554580473341\n",
      "  batch 3000 loss: 0.4065515527976677\n",
      "  batch 4000 loss: 0.3734308124186937\n",
      "  batch 5000 loss: 0.39652351212128994\n",
      "  batch 6000 loss: 0.3850455544523429\n",
      "  batch 7000 loss: 0.39464801391400395\n",
      "  batch 8000 loss: 0.36737369432626293\n",
      "  batch 9000 loss: 0.38146272763831074\n",
      "  batch 10000 loss: 0.39068819185905157\n",
      "  batch 11000 loss: 0.38443075365410184\n",
      "  batch 12000 loss: 0.3859093165548984\n",
      "  batch 13000 loss: 0.37327987791656053\n",
      "  batch 14000 loss: 0.3843325339960866\n",
      "  batch 15000 loss: 0.36665017985983284\n",
      "LOSS train 0.36665017985983284 valid 0.385469526052475\n",
      "EPOCH 3:\n",
      "  batch 1000 loss: 0.34674382737698034\n",
      "  batch 2000 loss: 0.37249785270367286\n",
      "  batch 3000 loss: 0.3405299978677649\n",
      "  batch 4000 loss: 0.3665036079061683\n",
      "  batch 5000 loss: 0.35108627389394675\n",
      "  batch 6000 loss: 0.3734603190519265\n",
      "  batch 7000 loss: 0.34301158525655046\n",
      "  batch 8000 loss: 0.34947497289977036\n",
      "  batch 9000 loss: 0.3359829558217898\n",
      "  batch 10000 loss: 0.3343947576005012\n",
      "  batch 11000 loss: 0.33885780029185114\n",
      "  batch 12000 loss: 0.3168547011265182\n",
      "  batch 13000 loss: 0.3649836489823647\n",
      "  batch 14000 loss: 0.34334833216434346\n",
      "  batch 15000 loss: 0.35963597847113854\n",
      "LOSS train 0.35963597847113854 valid 0.3876756727695465\n",
      "EPOCH 4:\n",
      "  batch 1000 loss: 0.3192074133860879\n",
      "  batch 2000 loss: 0.3298603570251726\n",
      "  batch 3000 loss: 0.31791302193887533\n",
      "  batch 4000 loss: 0.30781452124158387\n",
      "  batch 5000 loss: 0.3295879192092689\n",
      "  batch 6000 loss: 0.31861458413954824\n",
      "  batch 7000 loss: 0.3199722233570064\n",
      "  batch 8000 loss: 0.33731557754043023\n",
      "  batch 9000 loss: 0.3405845007322496\n",
      "  batch 10000 loss: 0.32209897202654975\n",
      "  batch 11000 loss: 0.3224714977765107\n",
      "  batch 12000 loss: 0.3082023111960443\n",
      "  batch 13000 loss: 0.32147062245046254\n",
      "  batch 14000 loss: 0.3366740883907769\n",
      "  batch 15000 loss: 0.32434971724246864\n",
      "LOSS train 0.32434971724246864 valid 0.35985854268074036\n",
      "EPOCH 5:\n",
      "  batch 1000 loss: 0.3156291691857914\n",
      "  batch 2000 loss: 0.3010066432398162\n",
      "  batch 3000 loss: 0.28819181994567045\n",
      "  batch 4000 loss: 0.3141706088013598\n",
      "  batch 5000 loss: 0.2928515595674107\n",
      "  batch 6000 loss: 0.29791806559765244\n",
      "  batch 7000 loss: 0.3114394273041689\n",
      "  batch 8000 loss: 0.2790222849368583\n",
      "  batch 9000 loss: 0.29938683584239334\n",
      "  batch 10000 loss: 0.3139824904461857\n",
      "  batch 11000 loss: 0.3133428309192823\n",
      "  batch 12000 loss: 0.3248469991259044\n",
      "  batch 13000 loss: 0.30770346811097987\n",
      "  batch 14000 loss: 0.3046316759791225\n",
      "  batch 15000 loss: 0.3060992963284371\n",
      "LOSS train 0.3060992963284371 valid 0.36316978931427\n"
     ]
    }
   ],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "epoch_number = 0\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch_number + 1))\n",
    "\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch_number, writer)\n",
    "\n",
    "    running_vloss = 0.0\n",
    "    # Set the model to evaluation mode, disabling dropout and using population\n",
    "    # statistics for batch normalization.\n",
    "    model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(validation_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = model(vinputs)\n",
    "            vloss = loss_fn(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch\n",
    "    # for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch_number + 1)\n",
    "    writer.flush()\n",
    "\n",
    "    # Track best performance, and save the model's state\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    epoch_number += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
